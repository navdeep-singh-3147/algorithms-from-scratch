{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a0594e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "examples: list[list[int]] = [[1, 2, 3, 4, 9, 2, 5, 6, 7], [5, 2, 1, 3, 7, 11, 23, 21], [4, 2, 8]]\n",
    "max_seq_len: int = 8\n",
    "pad_token_id: int = -100\n",
    "eos_token_id: int = 99\n",
    "\n",
    "stream_input_ids = []\n",
    "stream_position_ids = []\n",
    "stream_seq_ids = []\n",
    "\n",
    "current_global_seq_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c13c9987",
   "metadata": {},
   "outputs": [],
   "source": [
    "for seq in examples:\n",
    "    seq_len = len(seq)\n",
    "    \n",
    "    # 1. Input IDs = Seq + EOS token\n",
    "    full_seq = seq + [eos_token_id]\n",
    "    stream_input_ids.extend(full_seq)\n",
    "    \n",
    "    # 2. Position IDs: [0, 1, 2, 3, 4,..., len-1]\n",
    "    # Crucial for RoPE! We reset to 0 for every new sequence.\n",
    "    pos_ids = list(range(len(full_seq)))\n",
    "    stream_position_ids.extend(pos_ids)\n",
    "    \n",
    "    # 3.Sequence IDs: [0, 0 ,0,..] then [1, 1, 1,..]\n",
    "    stream_seq_ids.extend([current_global_seq_id] * len(full_seq))\n",
    "    current_global_seq_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2df75f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stream_input_ids: [1, 2, 3, 4, 9, 2, 5, 6, 7, 99, 5, 2, 1, 3, 7, 11, 23, 21, 99, 4, 2, 8, 99]\n",
      "stream_position_ids: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 0, 1, 2, 3]\n",
      "stream_seq_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "print(f\"stream_input_ids: {stream_input_ids}\")\n",
    "print(f\"stream_position_ids: {stream_position_ids}\")\n",
    "print(f\"stream_seq_ids: {stream_seq_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "be802db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Chunk the stream into blocks of max_len\n",
    "packed_input_batches = []\n",
    "packed_pos_batches = []\n",
    "packed_seq_batches = []\n",
    "\n",
    "total_tokens = len(stream_input_ids)\n",
    "\n",
    "for i in range(0, total_tokens, max_seq_len):\n",
    "    end_idx = i + max_seq_len\n",
    "    chunk_input = stream_input_ids[i:end_idx]\n",
    "    chunk_pos = stream_position_ids[i:end_idx]\n",
    "    chunk_seq = stream_seq_ids[i:end_idx]\n",
    "    \n",
    "    if len(chunk_input) < max_seq_len:\n",
    "        pad_len = max_seq_len - len(chunk_input)\n",
    "        chunk_input.extend([pad_token_id] * pad_len)\n",
    "        chunk_pos.extend([pad_token_id] * pad_len)\n",
    "        chunk_seq.extend([pad_token_id] * pad_len)\n",
    "        \n",
    "    packed_input_batches.append(chunk_input)\n",
    "    packed_pos_batches.append(chunk_pos)\n",
    "    packed_seq_batches.append(chunk_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2136b2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_tokens: 23\n",
      "packed_input_batches: [[1, 2, 3, 4, 9, 2, 5, 6], [7, 99, 5, 2, 1, 3, 7, 11], [23, 21, 99, 4, 2, 8, 99, -100]]\n",
      "packed_pos_batches: [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 0, 1, 2, 3, 4, 5], [6, 7, 8, 0, 1, 2, 3, -100]]\n",
      "packed_seq_batches: [[0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 1, 1, 1, 1, 1], [1, 1, 1, 2, 2, 2, 2, -100]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"total_tokens: {total_tokens}\")\n",
    "\n",
    "print(f\"packed_input_batches: {packed_input_batches}\")\n",
    "print(f\"packed_pos_batches: {packed_pos_batches}\")\n",
    "print(f\"packed_seq_batches: {packed_seq_batches}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8fb3b45f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[   1,    2,    3,    4,    9,    2,    5,    6],\n",
       "         [   7,   99,    5,    2,    1,    3,    7,   11],\n",
       "         [  23,   21,   99,    4,    2,    8,   99, -100]]),\n",
       " 'position_ids': tensor([[   0,    1,    2,    3,    4,    5,    6,    7],\n",
       "         [   8,    9,    0,    1,    2,    3,    4,    5],\n",
       "         [   6,    7,    8,    0,    1,    2,    3, -100]]),\n",
       " 'seq_ids': tensor([[   0,    0,    0,    0,    0,    0,    0,    0],\n",
       "         [   0,    0,    1,    1,    1,    1,    1,    1],\n",
       "         [   1,    1,    1,    2,    2,    2,    2, -100]])}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packed_data = {\n",
    "    \"input_ids\": torch.tensor(packed_input_batches, dtype=torch.long),\n",
    "    \"position_ids\": torch.tensor(packed_pos_batches, dtype=torch.long),\n",
    "    \"seq_ids\": torch.tensor(packed_seq_batches, dtype=torch.long)\n",
    "}\n",
    "packed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "72cba6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PackedDataset(Dataset):\n",
    "    def __init__(self, packed_data):\n",
    "        self.input_ids = packed_data[\"input_ids\"]\n",
    "        self.position_ids = packed_data[\"position_ids\"]\n",
    "        self.seq_ids = packed_data[\"seq_ids\"]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return {\n",
    "            \"input_ids\": self.input_ids[index],\n",
    "            \"position_ids\": self.position_ids[index],\n",
    "            \"seq_ids\": self.seq_ids[index]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c67a58c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([  23,   21,   99,    4,    2,    8,   99, -100]),\n",
       " 'position_ids': tensor([   6,    7,    8,    0,    1,    2,    3, -100]),\n",
       " 'seq_ids': tensor([   1,    1,    1,    2,    2,    2,    2, -100])}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = PackedDataset(packed_data=packed_data)\n",
    "\n",
    "training_data[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8697a8e",
   "metadata": {},
   "source": [
    "### Mask Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "407e2acf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 8)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_ids = packed_data[\"seq_ids\"]\n",
    "\n",
    "bsz, seq_len = seq_ids.shape\n",
    "bsz, seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "83810c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[   0],\n",
       "         [   0],\n",
       "         [   0],\n",
       "         [   0],\n",
       "         [   0],\n",
       "         [   0],\n",
       "         [   0],\n",
       "         [   0]],\n",
       "\n",
       "        [[   0],\n",
       "         [   0],\n",
       "         [   1],\n",
       "         [   1],\n",
       "         [   1],\n",
       "         [   1],\n",
       "         [   1],\n",
       "         [   1]],\n",
       "\n",
       "        [[   1],\n",
       "         [   1],\n",
       "         [   1],\n",
       "         [   2],\n",
       "         [   2],\n",
       "         [   2],\n",
       "         [   2],\n",
       "         [-100]]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Step 1: Expand IDs to create a grid for comparison\n",
    "# ---------------------------------------------------------\n",
    "# We want to compare every token against every other token.\n",
    "# Shape: (Batch, Seq_Len, 1)\n",
    "\n",
    "seq_ids_row = seq_ids.unsqueeze(-1)\n",
    "seq_ids_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bbd66464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[   0,    0,    0,    0,    0,    0,    0,    0]],\n",
       "\n",
       "        [[   0,    0,    1,    1,    1,    1,    1,    1]],\n",
       "\n",
       "        [[   1,    1,    1,    2,    2,    2,    2, -100]]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape: (Batch, 1, Seq_Len)\n",
    "seq_ids_col = seq_ids.unsqueeze(-2)\n",
    "seq_ids_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cd474954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True]],\n",
       "\n",
       "        [[ True,  True, False, False, False, False, False, False],\n",
       "         [ True,  True, False, False, False, False, False, False],\n",
       "         [False, False,  True,  True,  True,  True,  True,  True],\n",
       "         [False, False,  True,  True,  True,  True,  True,  True],\n",
       "         [False, False,  True,  True,  True,  True,  True,  True],\n",
       "         [False, False,  True,  True,  True,  True,  True,  True],\n",
       "         [False, False,  True,  True,  True,  True,  True,  True],\n",
       "         [False, False,  True,  True,  True,  True,  True,  True]],\n",
       "\n",
       "        [[ True,  True,  True, False, False, False, False, False],\n",
       "         [ True,  True,  True, False, False, False, False, False],\n",
       "         [ True,  True,  True, False, False, False, False, False],\n",
       "         [False, False, False,  True,  True,  True,  True, False],\n",
       "         [False, False, False,  True,  True,  True,  True, False],\n",
       "         [False, False, False,  True,  True,  True,  True, False],\n",
       "         [False, False, False,  True,  True,  True,  True, False],\n",
       "         [False, False, False, False, False, False, False, False]]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Step 2: Create the \"Same Sequence\" Mask (Block Diagonal)\n",
    "# ---------------------------------------------------------\n",
    "# Check: Does Token[i] belong to the same sequence as Token[j]?\n",
    "# Result: (Batch, Seq_Len, Seq_Len) boolean matrix\n",
    "# We also check (seq_ids_col != -1) to ensure we never attend to padding.\n",
    "\n",
    "same_seq_mask = (seq_ids_row == seq_ids_col) & (seq_ids_col != -100)\n",
    "same_seq_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7f2af251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False, False, False, False, False, False, False],\n",
       "        [ True,  True, False, False, False, False, False, False],\n",
       "        [ True,  True,  True, False, False, False, False, False],\n",
       "        [ True,  True,  True,  True, False, False, False, False],\n",
       "        [ True,  True,  True,  True,  True, False, False, False],\n",
       "        [ True,  True,  True,  True,  True,  True, False, False],\n",
       "        [ True,  True,  True,  True,  True,  True,  True, False],\n",
       "        [ True,  True,  True,  True,  True,  True,  True,  True]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Step 3: Create the \"Causal\" Mask (Lower Triangular)\n",
    "# ---------------------------------------------------------\n",
    "# Standard look-ahead mask. \n",
    "# torch.tril returns the lower triangular part (ones on and below diagonal)\n",
    "# We create a generic (Seq_Len, Seq_Len) matrix and broadcast it.\n",
    "causal_mask = torch.tril(torch.ones(seq_len, seq_len, device=seq_ids.device)).bool()\n",
    "causal_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6b7c2332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Step 4: Combine Masks\n",
    "# ---------------------------------------------------------\n",
    "# A token is visible IF (Same Sequence) AND (In the Past)\n",
    "combined_mask = same_seq_mask & causal_mask\n",
    "combined_mask = combined_mask.unsqueeze(1) # (batch_size, 1, seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dfeaa001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0.]]]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Step 5: Convert to Additive Attention Mask\n",
    "# ---------------------------------------------------------\n",
    "# In PyTorch attention, we add 0.0 to scores we keep, and -inf to scores we kill.\n",
    "# Start with a container of all zeros\n",
    "\n",
    "dtype = torch.float32\n",
    "\n",
    "final_mask = torch.zeros((bsz, 1, seq_len, seq_len), dtype=dtype, device=seq_ids.device)\n",
    "final_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ccfc2bd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ True, False, False, False, False, False, False, False],\n",
       "          [ True,  True, False, False, False, False, False, False],\n",
       "          [ True,  True,  True, False, False, False, False, False],\n",
       "          [ True,  True,  True,  True, False, False, False, False],\n",
       "          [ True,  True,  True,  True,  True, False, False, False],\n",
       "          [ True,  True,  True,  True,  True,  True, False, False],\n",
       "          [ True,  True,  True,  True,  True,  True,  True, False],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True]]],\n",
       "\n",
       "\n",
       "        [[[ True, False, False, False, False, False, False, False],\n",
       "          [ True,  True, False, False, False, False, False, False],\n",
       "          [False, False,  True, False, False, False, False, False],\n",
       "          [False, False,  True,  True, False, False, False, False],\n",
       "          [False, False,  True,  True,  True, False, False, False],\n",
       "          [False, False,  True,  True,  True,  True, False, False],\n",
       "          [False, False,  True,  True,  True,  True,  True, False],\n",
       "          [False, False,  True,  True,  True,  True,  True,  True]]],\n",
       "\n",
       "\n",
       "        [[[ True, False, False, False, False, False, False, False],\n",
       "          [ True,  True, False, False, False, False, False, False],\n",
       "          [ True,  True,  True, False, False, False, False, False],\n",
       "          [False, False, False,  True, False, False, False, False],\n",
       "          [False, False, False,  True,  True, False, False, False],\n",
       "          [False, False, False,  True,  True,  True, False, False],\n",
       "          [False, False, False,  True,  True,  True,  True, False],\n",
       "          [False, False, False, False, False, False, False, False]]]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f714d098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "          [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "          [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
       "          [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
       "          [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
       "          [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
       "          [0., 0., 0., 0., 0., 0., 0., -inf],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "          [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "          [-inf, -inf, 0., -inf, -inf, -inf, -inf, -inf],\n",
       "          [-inf, -inf, 0., 0., -inf, -inf, -inf, -inf],\n",
       "          [-inf, -inf, 0., 0., 0., -inf, -inf, -inf],\n",
       "          [-inf, -inf, 0., 0., 0., 0., -inf, -inf],\n",
       "          [-inf, -inf, 0., 0., 0., 0., 0., -inf],\n",
       "          [-inf, -inf, 0., 0., 0., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "          [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "          [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
       "          [-inf, -inf, -inf, 0., -inf, -inf, -inf, -inf],\n",
       "          [-inf, -inf, -inf, 0., 0., -inf, -inf, -inf],\n",
       "          [-inf, -inf, -inf, 0., 0., 0., -inf, -inf],\n",
       "          [-inf, -inf, -inf, 0., 0., 0., 0., -inf],\n",
       "          [-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf]]]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0 means Normal bcz it adds to attention scores\n",
    "# -inf add to attention scores and make scores infinite and then softmax convert it to zero.\n",
    "\n",
    "\n",
    "final = final_mask.masked_fill(~combined_mask, value=float(\"-inf\"))\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c64ce1b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 8, 8])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ffb2cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84ca8e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack_sequences(sequences, max_len, eos_id):\n",
    "    buffer_input_ids = []\n",
    "    buffer_position_ids = []\n",
    "    buffer_seq_ids = []\n",
    "    \n",
    "    current_seq_id = 0\n",
    "    \n",
    "    for seq in sequences:\n",
    "        seq_len = len(seq)\n",
    "        \n",
    "        # 1. Input IDs = Seq + EOS token\n",
    "        full_seq = seq + [eos_id]\n",
    "        buffer_input_ids.extend(full_seq)\n",
    "        \n",
    "        # 2. Position IDs: [0, 1, 2, 3, 4,..., len-1]\n",
    "        # Crucial for RoPE! We reset to 0 for every new sequence.\n",
    "        pos_ids = list(range(len(full_seq)))\n",
    "        buffer_position_ids.extend(pos_ids)\n",
    "        \n",
    "        # 3.Sequence IDs: [0, 0 ,0,..] then [1, 1, 1,..]\n",
    "        buffer_seq_ids.extend([current_seq_id] * len(full_seq))\n",
    "        current_seq_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2820ddad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.full((10, 10), float(\"-inf\"))\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "21995094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.triu(mask, diagonal=1)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904257ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
